{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2541bbd-2b4f-46b9-aaf5-0a35ee249d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f555e8a-f283-4bb4-a01e-d8db3aec6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = download_image(\"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfc3d6d-5e10-4236-a33d-56a44a4c2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = prepare_image(img, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cef96f-fe8b-42c5-b7c3-0eb7f334f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(img.resize((224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7aad009-5585-462d-8539-e68987aea648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 61, 104,  22],\n",
       "        [ 59, 104,  23],\n",
       "        [ 61, 108,  28],\n",
       "        ...,\n",
       "        [ 59,  88,   0],\n",
       "        [ 55,  83,   0],\n",
       "        [ 53,  80,   1]],\n",
       "\n",
       "       [[ 66, 109,  29],\n",
       "        [ 61, 104,  25],\n",
       "        [ 65, 107,  31],\n",
       "        ...,\n",
       "        [ 60,  84,   0],\n",
       "        [ 54,  79,   0],\n",
       "        [ 55,  82,   5]],\n",
       "\n",
       "       [[ 66, 108,  32],\n",
       "        [ 66, 108,  34],\n",
       "        [ 68, 108,  35],\n",
       "        ...,\n",
       "        [ 59,  82,   0],\n",
       "        [ 61,  84,   6],\n",
       "        [ 54,  78,   2]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 27,  49,  11],\n",
       "        [ 29,  54,  14],\n",
       "        [ 31,  57,  10],\n",
       "        ...,\n",
       "        [221, 230, 229],\n",
       "        [217, 227, 226],\n",
       "        [220, 230, 229]],\n",
       "\n",
       "       [[ 26,  48,  10],\n",
       "        [ 26,  51,   9],\n",
       "        [ 29,  55,  10],\n",
       "        ...,\n",
       "        [222, 231, 230],\n",
       "        [222, 234, 232],\n",
       "        [227, 239, 237]],\n",
       "\n",
       "       [[ 28,  48,  11],\n",
       "        [ 23,  48,   8],\n",
       "        [ 21,  46,   4],\n",
       "        ...,\n",
       "        [221, 231, 230],\n",
       "        [226, 236, 235],\n",
       "        [222, 234, 232]]], shape=(224, 224, 3), dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965b671d-9f38-49f9-9093-7876edd211af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad9548e-e885-470c-829d-cec19cec4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) # ImageNet normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7838b02-76d1-4e92-8c0a-ee3ffce4533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_transforms(img)\n",
    "\n",
    "batch_t = torch.unsqueeze(x, 0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(batch_t)\n",
    "\n",
    "_, indices = torch.sort(output, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de64b1a1-dc8a-46c2-89c2-654ce6b1d60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[585, 903, 542, 650, 819, 457, 836, 752, 971, 837, 683, 982, 948, 641,\n",
       "         490, 723, 419, 610, 420, 523, 852, 487, 984, 459, 580, 589, 489, 902,\n",
       "         402, 681, 834, 929, 711, 429, 432, 401, 633, 488, 552, 898, 455, 722,\n",
       "         566, 916, 531, 714, 424, 907, 988, 981, 678, 793, 841, 541, 513, 594,\n",
       "         785, 818, 937, 558, 638, 889, 776, 768, 911, 823, 824, 445, 456, 543,\n",
       "         596, 617, 486, 737, 954, 747, 838, 265, 624, 699, 440, 315, 560, 826,\n",
       "         546, 608, 620, 840, 474, 464, 622, 323, 788, 579, 740, 892, 652, 631,\n",
       "         266, 872, 578, 183, 664, 574, 731, 639, 939, 409, 642, 364, 953, 504,\n",
       "         221, 743, 267, 587,  61, 947, 845, 618, 733, 590, 463, 853, 568, 703,\n",
       "          90, 998, 616, 843, 515, 679, 181, 480, 968, 605, 951, 591, 862, 736,\n",
       "         851, 716, 696, 584, 177, 905, 629, 434, 499, 735,  55, 310, 855, 881,\n",
       "         219, 418, 906, 413, 764, 599, 655, 875, 904, 813, 936, 491, 626, 522,\n",
       "         712, 506, 727, 965, 201, 956, 421, 761, 160, 530, 966, 593, 454, 112,\n",
       "         677, 503, 613, 549, 498, 630, 502, 643, 749,  71, 321, 636, 557, 772,\n",
       "         666, 667, 842, 577, 632, 559, 975,  60, 501, 704, 987, 583, 932, 775,\n",
       "         551, 494, 879, 774, 514, 899, 850, 326, 943, 206, 604, 447, 213, 268,\n",
       "         438,  46,  59, 441, 958, 635, 815, 720, 762, 950, 769, 582, 562, 529,\n",
       "         452, 113, 924,  76, 451, 810, 784, 944, 886, 512, 340, 426, 475, 917,\n",
       "         782, 858, 794,  84, 398, 214, 202, 876, 433, 878, 910, 759, 770, 400,\n",
       "         673, 509, 572, 222, 783, 417, 309, 189, 313, 800, 854, 707, 805, 191,\n",
       "         435, 882, 787, 952, 808,  94, 835,  67, 767, 806,  39, 869, 184, 660,\n",
       "         658, 301, 348, 527, 305, 828, 646, 955, 217, 355, 938, 637, 228, 670,\n",
       "         644, 645, 732, 606, 375, 792, 695, 528, 399,  54, 919, 416, 829, 763,\n",
       "         738, 885, 465, 989, 461, 352, 246, 868,  56, 621, 684, 508, 507, 187,\n",
       "         890, 365, 614, 601, 748, 453, 721, 676, 197, 571, 159, 171, 428, 397,\n",
       "         497, 996, 685, 648, 199, 880, 921, 236,  74, 773, 526, 934, 204, 316,\n",
       "         169,  36, 909, 306,  47, 176, 883,  23,  40, 623,  96, 887, 967, 319,\n",
       "         220, 188, 350, 478,  64, 816, 193, 969,  87, 240, 615, 443, 692, 462,\n",
       "         430, 105, 873, 865, 789, 728, 518, 211, 702, 760, 327, 124, 196,  50,\n",
       "         739, 353, 912, 312, 170, 308, 382, 985, 367, 598, 570, 946, 600, 381,\n",
       "         538, 436, 110, 825, 754, 195, 109, 755, 303, 226,  11, 999, 656, 973,\n",
       "         693, 791, 234, 253, 481, 304, 900, 178, 970, 216, 689, 146,  29, 439,\n",
       "         373,  77, 758, 243, 781, 860, 423, 200, 380, 983, 700, 961, 672, 799,\n",
       "         377,  89, 849, 378, 155,  52, 706,  63, 173, 158,  72, 995,  16, 972,\n",
       "         619, 172, 797, 918, 190,  14, 713, 978, 203, 602, 437, 897, 218, 786,\n",
       "         482, 691,  53, 412, 446, 473, 597, 114, 215,   7, 115, 254, 844, 647,\n",
       "         288,  19, 654, 945,  62, 468, 322, 390, 374, 252, 370, 719, 777, 496,\n",
       "         469, 682, 765, 198, 349, 334, 448, 611, 548, 801,  44, 744, 320, 671,\n",
       "         411,   4, 156, 427, 458, 592, 745, 442, 422, 238, 742, 831, 314, 665,\n",
       "         233, 809, 575, 545, 923, 311, 207, 931, 368, 239, 757, 980, 725, 235,\n",
       "          92, 118, 718, 822, 224, 293, 563, 192, 553, 771, 662,  58,  75, 859,\n",
       "         519, 329,  43, 414, 237, 359, 410, 209, 483,  70, 318, 979, 186,  79,\n",
       "         372,  69, 517, 708, 185, 524, 444, 362, 830, 317, 920, 479, 363, 709,\n",
       "         358, 756, 861,  91, 627, 251,  51, 122, 282, 351, 977, 408, 884, 150,\n",
       "         866, 567, 730, 957, 175, 715,  35, 356, 231, 697,  78,  31, 151, 290,\n",
       "          88, 994, 964, 893, 511, 698, 205, 877, 485, 922,  37, 525,   2, 154,\n",
       "          27, 331,  12, 291, 229, 779,  95, 333, 425, 472, 241, 870, 807,  45,\n",
       "          86, 569,  65, 680,  82,  24, 990, 153, 595, 337, 471, 339,  17,  15,\n",
       "           8, 993, 149, 324, 225, 285, 135, 119, 609, 258, 245, 396, 848,  20,\n",
       "         705,  42, 795,   1, 935, 262, 232, 376,   9, 247, 415, 307,  73, 208,\n",
       "          68, 539, 790, 281, 821, 157, 505, 997, 136,  85,  18, 164, 659,  32,\n",
       "         379, 612, 127, 325, 242, 701, 180, 949, 194, 533, 361, 292, 798, 933,\n",
       "         230, 928, 516,  34,   0, 649, 581, 212, 366, 255, 302, 125, 140, 103,\n",
       "         163, 343, 338, 121,  10, 345, 925, 102, 354, 778, 248, 657, 104, 165,\n",
       "         962, 123,  28, 717, 653, 888, 555, 168, 300, 753, 393, 476,   6, 661,\n",
       "          13, 369, 100, 974, 107, 470, 120, 357, 256, 166,  21, 371,  99,  22,\n",
       "         669, 817, 152, 449, 896, 108, 117, 561, 534, 603,  93, 520, 182, 536,\n",
       "         846, 796, 139, 894, 668, 839, 915, 273, 992, 688, 586, 460, 332, 959,\n",
       "          38, 746, 407, 942, 674, 179, 388, 847, 111, 227,   3, 634,  49, 750,\n",
       "          33, 286, 257, 741, 250, 863,  30, 405, 857, 532, 138, 210, 804, 687,\n",
       "         976,   5, 926, 544, 101, 726,  66, 495, 330, 336, 940, 385, 510, 908,\n",
       "         663, 328, 167, 275, 284, 128, 675, 289, 856, 133, 106, 272, 521, 260,\n",
       "         550, 466, 174, 126, 406, 450, 832, 244, 891, 901, 734, 145,  57, 335,\n",
       "          41, 259, 556, 913, 264,  97, 694,  25, 963, 392,  26, 249, 751, 384,\n",
       "         383, 492, 162, 131, 930, 394, 386, 535, 223, 986, 812, 493, 274, 360,\n",
       "         565, 724, 347, 588, 344, 143, 467, 927, 867, 298, 827, 346, 960, 710,\n",
       "         780, 576, 564,  48, 628, 132, 299, 261, 129, 142, 295,  83, 389, 137,\n",
       "         269, 477, 500, 391, 607, 141, 640, 803, 263, 287, 864, 395, 283, 161,\n",
       "         820, 690, 573, 991, 271,  81, 484, 941, 134, 148, 729, 811, 280, 116,\n",
       "         144, 294, 540, 554, 387,  80, 895, 278, 297, 651, 766, 277, 342, 147,\n",
       "         279, 130, 686, 547, 874, 270, 276, 403, 431, 341, 404, 871, 296, 814,\n",
       "         914, 802, 537, 625, 833,  98]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3865508-da22-4ad6-8fd7-4535fa7203d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048e2dbb-150a-4c92-81cb-c1bfeeebc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('picture.jpeg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b85456-e26e-4646-854b-7e8120ff4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78046a87-fdd2-4c26-9f2f-87f440d3136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52156866, -0.18431371, -0.827451  ],\n",
       "       [-0.5372549 , -0.18431371, -0.81960785],\n",
       "       [-0.52156866, -0.15294117, -0.78039217],\n",
       "       [-0.4980392 , -0.1372549 , -0.7254902 ],\n",
       "       [-0.5058824 , -0.14509803, -0.7176471 ],\n",
       "       [-0.5137255 , -0.1607843 , -0.7019608 ],\n",
       "       [-0.4980392 , -0.16862744, -0.6862745 ],\n",
       "       [-0.5058824 , -0.17647058, -0.6784314 ],\n",
       "       [-0.54509807, -0.19215685, -0.7019608 ],\n",
       "       [-0.4980392 , -0.14509803, -0.654902  ],\n",
       "       [-0.45098037, -0.12941176, -0.6       ],\n",
       "       [-0.5294118 , -0.17647058, -0.62352943],\n",
       "       [-0.5529412 , -0.17647058, -0.6313726 ],\n",
       "       [-0.6       , -0.19999999, -0.64705884],\n",
       "       [-0.5058824 , -0.12156862, -0.5529412 ],\n",
       "       [-0.52156866, -0.15294117, -0.5764706 ],\n",
       "       [-0.5529412 , -0.18431371, -0.5921569 ],\n",
       "       [-0.54509807, -0.16862744, -0.5764706 ],\n",
       "       [-0.56078434, -0.18431371, -0.5921569 ],\n",
       "       [-0.56078434, -0.14509803, -0.5686275 ],\n",
       "       [-0.62352943, -0.20784312, -0.64705884],\n",
       "       [-0.5764706 , -0.18431371, -0.58431375],\n",
       "       [-0.58431375, -0.19215685, -0.5921569 ],\n",
       "       [-0.58431375, -0.19215685, -0.5921569 ],\n",
       "       [-0.654902  , -0.26274508, -0.6627451 ],\n",
       "       [-0.6       , -0.21568626, -0.58431375],\n",
       "       [-0.60784316, -0.23921567, -0.58431375],\n",
       "       [-0.62352943, -0.21568626, -0.5921569 ],\n",
       "       [-0.5921569 , -0.19999999, -0.58431375],\n",
       "       [-0.6       , -0.19215685, -0.5764706 ],\n",
       "       [-0.6156863 , -0.2235294 , -0.62352943],\n",
       "       [-0.5372549 , -0.12156862, -0.5294118 ],\n",
       "       [-0.5921569 , -0.21568626, -0.62352943],\n",
       "       [-0.4980392 , -0.08235294, -0.52156866],\n",
       "       [-0.5686275 , -0.1372549 , -0.58431375],\n",
       "       [-0.47450978, -0.04313725, -0.49019605],\n",
       "       [-0.4823529 , -0.06666666, -0.5058824 ],\n",
       "       [-0.46666664, -0.03529412, -0.49019605],\n",
       "       [-0.4588235 , -0.01960784, -0.4980392 ],\n",
       "       [-0.41960782,  0.0196079 , -0.4588235 ],\n",
       "       [-0.45098037,  0.05882359, -0.4588235 ],\n",
       "       [-0.38823527,  0.10588241, -0.45098037],\n",
       "       [-0.3098039 ,  0.18431377, -0.36470586],\n",
       "       [-0.3333333 ,  0.16078436, -0.3960784 ],\n",
       "       [-0.27843136,  0.22352946, -0.35686272],\n",
       "       [-0.3333333 ,  0.15294123, -0.41960782],\n",
       "       [-0.27058822,  0.20000005, -0.3490196 ],\n",
       "       [-0.2235294 ,  0.26274514, -0.32549018],\n",
       "       [-0.17647058,  0.30980396, -0.29411763],\n",
       "       [-0.14509803,  0.3411765 , -0.26274508],\n",
       "       [-0.10588235,  0.34901965, -0.23137254],\n",
       "       [-0.05098039,  0.36470592, -0.18431371],\n",
       "       [-0.02745098,  0.41176474, -0.14509803],\n",
       "       [ 0.04313731,  0.45882356, -0.09019607],\n",
       "       [ 0.02745104,  0.427451  , -0.09803921],\n",
       "       [ 0.10588241,  0.5137255 , -0.00392157],\n",
       "       [ 0.18431377,  0.5686275 ,  0.05098045],\n",
       "       [ 0.38823533,  0.64705884,  0.21568632],\n",
       "       [ 0.5372549 ,  0.6627451 ,  0.37254906],\n",
       "       [ 0.62352943,  0.70980394,  0.45882356],\n",
       "       [ 0.7411765 ,  0.79607844,  0.5529412 ],\n",
       "       [ 0.8745098 ,  0.8666667 ,  0.64705884],\n",
       "       [ 0.88235295,  0.8509804 ,  0.6392157 ],\n",
       "       [ 0.85882354,  0.85882354,  0.6392157 ],\n",
       "       [ 0.85882354,  0.8509804 ,  0.6156863 ],\n",
       "       [ 0.88235295,  0.8745098 ,  0.6392157 ],\n",
       "       [ 0.8980392 ,  0.90588236,  0.654902  ],\n",
       "       [ 0.8901961 ,  0.88235295,  0.6392157 ],\n",
       "       [ 0.8901961 ,  0.8901961 ,  0.62352943],\n",
       "       [ 0.84313726,  0.79607844,  0.5137255 ],\n",
       "       [ 0.75686276,  0.654902  ,  0.3803922 ],\n",
       "       [ 0.654902  ,  0.5372549 ,  0.21568632],\n",
       "       [ 0.7254902 ,  0.5921569 ,  0.254902  ],\n",
       "       [ 0.8666667 ,  0.75686276,  0.4666667 ],\n",
       "       [ 0.90588236,  0.827451  ,  0.5529412 ],\n",
       "       [ 0.9372549 ,  0.81960785,  0.5764706 ],\n",
       "       [ 0.92156863,  0.81960785,  0.5529412 ],\n",
       "       [ 0.8666667 ,  0.73333335,  0.49803925],\n",
       "       [ 0.8901961 ,  0.7411765 ,  0.5058824 ],\n",
       "       [ 0.79607844,  0.6392157 ,  0.36470592],\n",
       "       [ 0.8509804 ,  0.6862745 ,  0.47450984],\n",
       "       [ 0.654902  ,  0.49803925,  0.28627455],\n",
       "       [ 0.17647064, -0.02745098, -0.2862745 ],\n",
       "       [ 0.12941182, -0.1372549 , -0.35686272],\n",
       "       [-0.00392157, -0.25490195, -0.4352941 ],\n",
       "       [ 0.41176474,  0.20000005, -0.01176471],\n",
       "       [ 0.09019613, -0.18431371, -0.41960782],\n",
       "       [ 0.27058828,  0.06666672, -0.2235294 ],\n",
       "       [ 0.6       ,  0.43529415,  0.20784318],\n",
       "       [ 0.67058825,  0.5764706 ,  0.4039216 ],\n",
       "       [ 0.62352943,  0.5058824 ,  0.3411765 ],\n",
       "       [ 0.4666667 ,  0.37254906,  0.18431377],\n",
       "       [ 0.23921573,  0.082353  , -0.11372548],\n",
       "       [ 0.2313726 ,  0.0196079 , -0.20784312],\n",
       "       [ 0.03529418, -0.18431371, -0.3490196 ],\n",
       "       [ 0.45882356,  0.24705887,  0.03529418],\n",
       "       [ 0.36470592,  0.11372554, -0.08235294],\n",
       "       [ 0.2941177 ,  0.12156868, -0.04313725],\n",
       "       [ 0.7647059 ,  0.60784316,  0.39607847],\n",
       "       [ 0.41176474,  0.24705887,  0.0196079 ],\n",
       "       [ 0.27058828,  0.06666672, -0.12941176],\n",
       "       [ 0.39607847,  0.18431377,  0.05098045],\n",
       "       [ 0.30980396,  0.16078436,  0.02745104],\n",
       "       [ 0.45882356,  0.3176471 ,  0.16078436],\n",
       "       [ 0.60784316,  0.4431373 ,  0.27843142],\n",
       "       [ 0.3803922 ,  0.22352946,  0.03529418],\n",
       "       [ 0.26274514,  0.13725495, -0.05882353],\n",
       "       [ 0.4039216 ,  0.2313726 ,  0.05098045],\n",
       "       [ 0.33333337,  0.17647064, -0.01176471],\n",
       "       [ 0.20000005,  0.06666672, -0.1372549 ],\n",
       "       [ 0.4666667 ,  0.30980396,  0.09803927],\n",
       "       [ 0.56078434,  0.4039216 ,  0.19215691],\n",
       "       [ 0.52156866,  0.35686278,  0.14509809],\n",
       "       [ 0.41960788,  0.24705887,  0.05882359],\n",
       "       [ 0.48235297,  0.26274514,  0.09019613],\n",
       "       [ 0.43529415,  0.2313726 ,  0.05098045],\n",
       "       [ 0.60784316,  0.41176474,  0.17647064],\n",
       "       [ 0.41176474,  0.20000005, -0.01176471],\n",
       "       [ 0.5137255 ,  0.33333337,  0.082353  ],\n",
       "       [ 0.2313726 ,  0.01176476, -0.17647058],\n",
       "       [ 0.2941177 ,  0.05098045, -0.11372548],\n",
       "       [ 0.10588241, -0.09019607, -0.26274508],\n",
       "       [ 0.47450984,  0.33333337,  0.17647064],\n",
       "       [ 0.8509804 ,  0.75686276,  0.64705884],\n",
       "       [ 0.6313726 ,  0.5686275 ,  0.48235297],\n",
       "       [ 0.7647059 ,  0.6862745 ,  0.5921569 ],\n",
       "       [ 0.49803925,  0.37254906,  0.17647064],\n",
       "       [ 0.427451  ,  0.2313726 , -0.00392157],\n",
       "       [ 0.5294118 ,  0.37254906,  0.082353  ],\n",
       "       [ 0.41960788,  0.26274514, -0.02745098],\n",
       "       [ 0.47450984,  0.28627455,  0.00392163],\n",
       "       [ 0.2941177 ,  0.09803927, -0.14509803],\n",
       "       [ 0.13725495, -0.05882353, -0.29411763],\n",
       "       [ 0.09019613, -0.09019607, -0.35686272],\n",
       "       [ 0.19215691,  0.01176476, -0.23921567],\n",
       "       [ 0.37254906,  0.22352946, -0.01176471],\n",
       "       [ 0.5137255 ,  0.4039216 ,  0.20000005],\n",
       "       [ 0.6862745 ,  0.62352943,  0.4431373 ],\n",
       "       [ 0.827451  ,  0.7647059 ,  0.6627451 ],\n",
       "       [ 0.78039217,  0.7254902 ,  0.58431375],\n",
       "       [ 0.7490196 ,  0.69411767,  0.54509807],\n",
       "       [ 0.77254903,  0.6862745 ,  0.54509807],\n",
       "       [ 0.7882353 ,  0.7411765 ,  0.5686275 ],\n",
       "       [ 0.8352941 ,  0.7882353 ,  0.6       ],\n",
       "       [ 0.88235295,  0.81960785,  0.67058825],\n",
       "       [ 0.88235295,  0.85882354,  0.70980394],\n",
       "       [ 0.90588236,  0.8980392 ,  0.75686276],\n",
       "       [ 0.92941177,  0.88235295,  0.77254903],\n",
       "       [ 0.9764706 ,  0.9529412 ,  0.8352941 ],\n",
       "       [ 0.96862745,  0.9529412 ,  0.85882354],\n",
       "       [ 0.9529412 ,  0.9529412 ,  0.8745098 ],\n",
       "       [ 0.96862745,  0.9764706 ,  0.92941177],\n",
       "       [ 0.9843137 ,  0.9843137 ,  0.96862745],\n",
       "       [ 0.96862745,  0.96862745,  0.96862745],\n",
       "       [ 0.9372549 ,  0.9529412 ,  0.92941177],\n",
       "       [ 0.88235295,  0.8980392 ,  0.8745098 ],\n",
       "       [ 0.96862745,  0.9843137 ,  0.9764706 ],\n",
       "       [ 0.96862745,  0.96862745,  0.96862745],\n",
       "       [ 0.9764706 ,  0.9764706 ,  0.99215686],\n",
       "       [ 0.96862745,  0.9764706 ,  1.        ],\n",
       "       [ 0.96862745,  0.9764706 ,  1.        ],\n",
       "       [ 0.9372549 ,  0.96862745,  0.99215686],\n",
       "       [ 0.9372549 ,  0.96862745,  0.9764706 ],\n",
       "       [ 0.90588236,  0.9764706 ,  0.9529412 ],\n",
       "       [ 0.94509804,  0.9843137 ,  0.9529412 ],\n",
       "       [ 0.8980392 ,  0.9843137 ,  0.8509804 ],\n",
       "       [ 0.8352941 ,  0.9529412 ,  0.7254902 ],\n",
       "       [ 0.8117647 ,  0.9372549 ,  0.6313726 ],\n",
       "       [ 0.70980394,  0.88235295,  0.39607847],\n",
       "       [ 0.6627451 ,  0.8509804 ,  0.27058828],\n",
       "       [ 0.67058825,  0.8901961 ,  0.22352946],\n",
       "       [ 0.60784316,  0.8352941 ,  0.11372554],\n",
       "       [ 0.60784316,  0.8352941 , -0.02745098],\n",
       "       [ 0.5137255 ,  0.7647059 , -0.23137254],\n",
       "       [ 0.54509807,  0.81960785, -0.3098039 ],\n",
       "       [ 0.54509807,  0.79607844, -0.3490196 ],\n",
       "       [ 0.54509807,  0.8039216 , -0.38039213],\n",
       "       [ 0.56078434,  0.827451  , -0.40392154],\n",
       "       [ 0.49803925,  0.77254903, -0.4980392 ],\n",
       "       [ 0.5058824 ,  0.7490196 , -0.46666664],\n",
       "       [ 0.52156866,  0.78039217, -0.5137255 ],\n",
       "       [ 0.47450984,  0.7176471 , -0.5686275 ],\n",
       "       [ 0.45098042,  0.7019608 , -0.62352943],\n",
       "       [ 0.41960788,  0.67058825, -0.654902  ],\n",
       "       [ 0.4039216 ,  0.654902  , -0.67058825],\n",
       "       [ 0.43529415,  0.6862745 , -0.6392157 ],\n",
       "       [ 0.3803922 ,  0.62352943, -0.6784314 ],\n",
       "       [ 0.33333337,  0.5764706 , -0.7254902 ],\n",
       "       [ 0.3176471 ,  0.5686275 , -0.75686276],\n",
       "       [ 0.26274514,  0.5058824 , -0.78039217],\n",
       "       [ 0.28627455,  0.5294118 , -0.7490196 ],\n",
       "       [ 0.22352946,  0.45882356, -0.79607844],\n",
       "       [ 0.20000005,  0.43529415, -0.81960785],\n",
       "       [ 0.20784318,  0.4431373 , -0.79607844],\n",
       "       [ 0.19215691,  0.41176474, -0.8666667 ],\n",
       "       [ 0.18431377,  0.4039216 , -0.8745098 ],\n",
       "       [ 0.15294123,  0.3803922 , -0.92156863],\n",
       "       [ 0.09803927,  0.32549024, -0.9764706 ],\n",
       "       [ 0.09019613,  0.30196083, -0.99215686],\n",
       "       [ 0.09803927,  0.2941177 , -0.99215686],\n",
       "       [ 0.03529418,  0.23921573, -1.        ],\n",
       "       [ 0.05882359,  0.254902  , -0.96862745],\n",
       "       [ 0.01176476,  0.20784318, -1.        ],\n",
       "       [-0.02745098,  0.16078436, -1.        ],\n",
       "       [-0.00392157,  0.18431377, -0.9764706 ],\n",
       "       [ 0.01176476,  0.20000005, -0.9607843 ],\n",
       "       [-0.0745098 ,  0.10588241, -1.        ],\n",
       "       [-0.09019607,  0.09019613, -1.        ],\n",
       "       [-0.0745098 ,  0.11372554, -0.9843137 ],\n",
       "       [-0.1372549 ,  0.05098045, -1.        ],\n",
       "       [-0.17647058, -0.00392157, -1.        ],\n",
       "       [-0.21568626, -0.05098039, -0.9843137 ],\n",
       "       [-0.25490195, -0.0745098 , -0.99215686],\n",
       "       [-0.27058822, -0.08235294, -1.        ],\n",
       "       [-0.27843136, -0.09019607, -0.9843137 ],\n",
       "       [-0.3098039 , -0.12156862, -1.        ],\n",
       "       [-0.3333333 , -0.15294117, -1.        ],\n",
       "       [-0.3490196 , -0.16862744, -0.9843137 ],\n",
       "       [-0.41176468, -0.23921567, -1.        ],\n",
       "       [-0.44313723, -0.23137254, -0.9764706 ],\n",
       "       [-0.4588235 , -0.24705881, -0.9764706 ],\n",
       "       [-0.5372549 , -0.3098039 , -1.        ],\n",
       "       [-0.5686275 , -0.3490196 , -1.        ],\n",
       "       [-0.58431375, -0.372549  , -0.99215686]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=preprocess_input(x)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3e921ea-bc1d-4cf9-807a-b828a24d04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     dummy_input,\n",
    "#     onnx_path,\n",
    "#     verbose=True,\n",
    "#     input_names=['input'],\n",
    "#     output_names=['output'],\n",
    "#     dynamic_axes={\n",
    "#         'input': {0: 'batch_size'},\n",
    "#         'output': {0: 'batch_size'}\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11c23ac-84df-44cd-b539-ca52880a05bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: hair_classifier_v1.onnx\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ClothingClassifierMobileNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading model from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = \u001b[43mClothingClassifierMobileNet\u001b[49m(size_inner=\u001b[32m32\u001b[39m, droprate=\u001b[32m0.2\u001b[39m, num_classes=\u001b[32m10\u001b[39m)\n\u001b[32m     11\u001b[39m model.load_state_dict(torch.load(latest_file))\n\u001b[32m     12\u001b[39m model.to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'ClothingClassifierMobileNet' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Find best checkpoint\n",
    "list_of_files = glob.glob('hair_classifier_v1.onnx')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(f\"Loading model from: {latest_file}\")\n",
    "\n",
    "# Load model\n",
    "model = ClothingClassifierMobileNet(size_inner=32, droprate=0.2, num_classes=10)\n",
    "model.load_state_dict(torch.load(latest_file))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "875265bf-d94e-4494-b188-b9f2615eaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2fbbbb1-5790-4615-9bcb-3e4cc7f1e145",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m onnx_model = onnx.load(model_name)\n\u001b[32m      6\u001b[39m onnx.checker.check_model(onnx_model)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m resize = transforms.Compose(\n\u001b[32m     10\u001b[39m                 [ transforms.Resize((\u001b[32m200\u001b[39m,\u001b[32m200\u001b[39m)), transforms.ToTensor()])             \n\u001b[32m     11\u001b[39m image = resize(image)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\PIL\\Image.py:3513\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3512\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3513\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3514\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3515\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'"
     ]
    }
   ],
   "source": [
    "# !pip install onnx onnxruntime-gpu \n",
    "import onnx, onnxruntime\n",
    "\n",
    "model_name = 'hair_classifier_v1.onnx'\n",
    "onnx_model = onnx.load(model_name)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "image = Image.open('https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg')\n",
    "resize = transforms.Compose(\n",
    "                [ transforms.Resize((200,200)), transforms.ToTensor()])             \n",
    "image = resize(image)\n",
    "image = image.unsqueeze(0) # add fake batch dimension\n",
    "image = image.to(device)\n",
    "\n",
    "EP_list = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(model_name, providers=EP_list)\n",
    "\n",
    "def to_numpy(tensor):\n",
    "      return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "max = float('-inf')\n",
    "max_index = -1\n",
    "for i in range(0, len(ort_outs[0][0])):       \n",
    "   if(ort_outs[0][0][i] > max):    \n",
    "       max = ort_outs[0][0][i]\n",
    "       max_index = i\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f21252d1-1fa7-40cd-87ca-90dce2ad759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca6a0c49-caae-4923-98d8-03ab6514059e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(2.0972447)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69ec22c-26e6-4aa0-8baa-494d5bf70eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3af9928a-7833-419e-8f90-28e1ea8d76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = download_image(\"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd72f32b-eeed-4a17-b0bc-af5389f838b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = prepare_image(img2, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c4d9053-c094-4fb9-8fb2-2a75cd267909",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.save('picture2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ba53adf-d34b-4dc6-8f40-357b9f33e5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# !pip install onnx onnxruntime-gpu \n",
    "import onnx, onnxruntime\n",
    "\n",
    "model_name = 'hair_classifier_v1.onnx'\n",
    "onnx_model = onnx.load(model_name)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "image = Image.open('picture2.jpeg')\n",
    "resize = transforms.Compose(\n",
    "                [ transforms.Resize((200,200)), transforms.ToTensor()])             \n",
    "image = resize(image)\n",
    "image = image.unsqueeze(0) # add fake batch dimension\n",
    "image = image.to(device)\n",
    "\n",
    "EP_list = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(model_name, providers=EP_list)\n",
    "\n",
    "def to_numpy(tensor):\n",
    "      return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "max = float('-inf')\n",
    "max_index = -1\n",
    "for i in range(0, len(ort_outs[0][0])):       \n",
    "   if(ort_outs[0][0][i] > max):    \n",
    "       max = ort_outs[0][0][i]\n",
    "       max_index = i\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816f3f1-e51f-4619-84de-84c20e36b5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
